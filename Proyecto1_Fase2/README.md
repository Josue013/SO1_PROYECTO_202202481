
---
---
---

<p align="center"> 
<a href="https://git.io/typing-svg"><img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&size=25&pause=1000&color=00F7E4&center=true&vCenter=true&width=435&lines=*****+PROYECTO+%232+*****" alt="Typing SVG" /></a>
</p>

---
---
---


  <h3 align="center"><strong>Universidad de San Carlos de Guatemala</strong></h3>
  <h3 align="center"><strong>Facultad de Ingenier√≠a</strong></h3>
  <h3 align="center"><strong>Escuela de Ciencias y Sistemas</strong></h3>
  <h3 align="center"><strong>Lab. Sistemas Operativos 1</strong></h3>
  <h3 align="center"><strong>Secci√≥n: "A"</strong></h3>

---
---
---

<br>
<br>

# Manual T√©cnico Fase 2

<br>
<br>

| Nombre                           | Carnet      |
| -------------------------------- | ----------- |
| Josu√© Nab√≠ Hurtarte Pinto        | `202202481` |

---

## <a name="indice">üìÖ INDICE

|     | Titulo                      | Link         |
| --- | --------------------------- | ------------ |
| 1   | `Descripcion del proyecto`  | [IR](#desc)  |
| 2   | `Arquitectura del proyecto` | [IR](#arq)   |
| 3   | `Modulo de procesos`        | [IR](#pro)   |
| 4   | `Locust`                    | [IR](#loc)   |
| 5   | `Kubernetes`                | [IR](#kub)   |
| 6   | `Rutas`                     | [IR](#ru)    |
| 7   | `Socket.io`                 | [IR](#sktio) |
| 8   | `Cloud Sql`                 | [IR](#csql)  |
| 9   | `Cloud Run`                 | [IR](#crun)  |

---

## <a name="desc">1. Descripci√≥n del proyecto

### üìã Objetivo General

La **Fase 2** del proyecto Sistema de Monitoreo de Recursos evoluciona la arquitectura hacia una **soluci√≥n cloud-native completa**, implementando conceptos avanzados de DevOps, orquestaci√≥n de contenedores, microservicios y monitoreo en tiempo real. El objetivo es crear una infraestructura escalable y robusta utilizando Google Cloud Platform y tecnolog√≠as modernas de contenedores.

### üéØ Evoluci√≥n respecto a Fase 1

| **Aspecto**              | **Fase 1**                    | **Fase 2**                           |
|--------------------------|-------------------------------|--------------------------------------|
| **Infraestructura**     | Docker Compose local          | Google Kubernetes Engine (GKE)      |
| **Base de Datos**       | MySQL en contenedor           | Cloud SQL (MySQL administrado)      |
| **Escalabilidad**       | Monol√≠tico                     | Microservicios distribuidos         |
| **Balanceador**         | Sin balanceador                | NGINX + Traffic Split 50/50         |
| **Tiempo Real**         | Polling cada segundo           | WebSockets con Socket.io            |
| **Frontend**            | React b√°sico                   | React + Cloud Run + Tiempo Real     |
| **CI/CD**               | Manual                         | GitHub Actions automatizado         |
| **Monitoreo**           | Logs b√°sicos                   | Observabilidad completa              |

### üöÄ Funcionalidades Nuevas

#### **üåê Infraestructura Cloud-Native:**
- **Google Kubernetes Engine**: Orquestaci√≥n autom√°tica de contenedores
- **Cloud SQL**: Base de datos MySQL totalmente administrada
- **Cloud Run**: Despliegue serverless para frontend
- **Load Balancer**: Distribuci√≥n inteligente de tr√°fico

#### **‚öñÔ∏è Balanceador de Carga Avanzado:**
- **Traffic Split 50/50**: Distribuci√≥n equitativa entre APIs de Python y Node.js
- **NGINX Ingress**: Configuraci√≥n de rutas y balanceo autom√°tico
- **Health Checks**: Verificaci√≥n autom√°tica de estado de servicios
- **Failover**: Redirecci√≥n autom√°tica en caso de fallos

#### **üì° Tiempo Real con WebSockets:**
- **Socket.io**: Comunicaci√≥n bidireccional en tiempo real
- **API Node.js dedicada**: Servicio especializado para WebSockets
- **Frontend reactivo**: Actualizaciones instant√°neas sin polling
- **Escalabilidad horizontal**: M√∫ltiples instancias de APIs

#### **üìä Observabilidad Completa:**
- **Logs centralizados**: Agregaci√≥n de logs de todos los servicios
- **M√©tricas de sistema**: CPU, RAM, procesos en tiempo real
- **Health endpoints**: Monitoreo de estado de cada microservicio
- **Alertas autom√°ticas**: Notificaciones en caso de fallos

### üèóÔ∏è Arquitectura de Microservicios

La Fase 2 implementa una **arquitectura de microservicios distribuida**:

1. **VM Linux**: Sistema base con m√≥dulos de kernel para recolecci√≥n de m√©tricas
2. **Cluster GKE**: Orquestaci√≥n de 4 microservicios independientes
3. **Load Balancer**: NGINX que distribuye carga entre APIs
4. **APIs duales**: Python (FastAPI) + Node.js (Express) con traffic split
5. **Tiempo Real**: API Node.js especializada con Socket.io
6. **Frontend**: React en Cloud Run con WebSockets
7. **Base de Datos**: Cloud SQL MySQL con alta disponibilidad

### üéì Conceptos Implementados

- **Orquestaci√≥n de Contenedores**: Kubernetes en producci√≥n
- **Microservicios**: Servicios independientes y escalables
- **Load Balancing**: Distribuci√≥n inteligente de carga
- **Tiempo Real**: WebSockets para comunicaci√≥n instant√°nea
- **Cloud Computing**: Servicios administrados de Google Cloud
- **Observabilidad**: Monitoreo y logging distribuido

---

## <a name="arq">2. Arquitectura del proyecto

![arquitectura](./imgs/image.png)

### üîß Componentes Principales

| **Componente**     | **Tecnolog√≠a**      | **Funci√≥n**                             |
| ------------------ | ------------------- | --------------------------------------- |
| Maquina Virtual    | Ubuntu 22.04        | Sistema con m√≥dulos kernel              |
| Locust             | Python + Locust     | Generaci√≥n de carga y pruebas de estr√©s |
| Kubernetes Cluster | GKE                 | Orquestaci√≥n de microservicios          |
| Load Balancer      | NGINX Ingress       | Traffic split y balanceo                |
| Python API         | Flask               | Procesamiento de m√©tricas               |
| Node.js API        | Express             | API REST alternativa                    |
| Realtime API       | Node.js + Socket.io | WebSockets en tiempo real               |
| Frontend           | React + Cloud Run   | Interfaz de usuario                     |
| Database           | Cloud SQL MySQL     | Almacenamiento persistente              |

---

## <a name="pro">3. M√≥dulo de procesos

### üìã Objetivo del m√≥dulo
Proporcionar informaci√≥n detallada sobre los procesos del sistema operativo en tiempo real, incluyendo conteos por estado (corriendo, durmiendo, zombies, parados) y total de procesos. El m√≥dulo crea una interfaz en el sistema de archivos `/proc` que permite el acceso directo a las m√©tricas de procesos desde el espacio de usuario.

### ‚öôÔ∏è Funcionalidad del m√≥dulo

El m√≥dulo `procesos_202202481` implementa las siguientes caracter√≠sticas:

- **Iteraci√≥n completa de procesos**: Utiliza `for_each_process(task)` para recorrer todos los procesos del sistema
- **An√°lisis de estados**: Examina el campo `task->__state` de cada proceso para clasificarlos por estado
- **Detecci√≥n de zombies**: Verifica el campo `task->exit_state` para identificar procesos zombie
- **Conteo autom√°tico**: Calcula autom√°ticamente:
  - Total de procesos en el sistema
  - Procesos en estado corriendo (`TASK_RUNNING`)
  - Procesos durmiendo (`TASK_INTERRUPTIBLE` | `TASK_UNINTERRUPTIBLE`)
  - Procesos parados (`__TASK_STOPPED` | `__TASK_TRACED`)
  - Procesos zombie (`EXIT_ZOMBIE`)
- **Formato JSON**: Exporta toda la informaci√≥n en formato JSON estructurado para f√°cil consumo por aplicaciones
- **Interfaz `/proc`**: Crea el archivo `/proc/procesos_202202481` para acceso desde espacio de usuario

### üèóÔ∏è Algoritmo de clasificaci√≥n

El m√≥dulo implementa un algoritmo de clasificaci√≥n basado en las constantes del kernel:

1. **Iteraci√≥n de procesos**: Recorre la lista de procesos del kernel usando `for_each_process()`
2. **An√°lisis de estado principal**: Examina `task->__state` para determinar el estado actual
3. **Clasificaci√≥n por estado**:
   - `TASK_RUNNING (0x00000000)`: Proceso ejecut√°ndose o listo para ejecutar
   - `TASK_INTERRUPTIBLE (0x00000001)`: Proceso durmiendo, puede ser interrumpido por se√±ales
   - `TASK_UNINTERRUPTIBLE (0x00000002)`: Proceso durmiendo, no puede ser interrumpido
   - `__TASK_STOPPED (0x00000004)`: Proceso parado por se√±al
   - `__TASK_TRACED (0x00000008)`: Proceso siendo rastreado por debugger
4. **Detecci√≥n de zombies**: Verifica `task->exit_state & EXIT_ZOMBIE` independientemente del estado principal
5. **Conteo incremental**: Mantiene contadores separados para cada categor√≠a

### üìä Estados de procesos monitoreados

| **Estado**              | **Constante del Kernel**    | **Descripci√≥n**                           |
|-------------------------|----------------------------|-------------------------------------------|
| **Corriendo**           | `TASK_RUNNING`             | Proceso ejecut√°ndose o en cola de CPU    |
| **Durmiendo**           | `TASK_INTERRUPTIBLE`       | Esperando evento, puede ser interrumpido |
| **Durmiendo profundo**  | `TASK_UNINTERRUPTIBLE`     | Esperando I/O, no puede ser interrumpido |
| **Parado**              | `__TASK_STOPPED`           | Detenido por se√±al (SIGSTOP, SIGTSTP)    |
| **Rastreado**           | `__TASK_TRACED`            | Bajo control de debugger (gdb, strace)   |
| **Zombie**              | `EXIT_ZOMBIE`              | Proceso terminado esperando recolecci√≥n   |

### üíª C√≥digo del m√≥dulo

```c
#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/init.h>
#include <linux/proc_fs.h>
#include <linux/seq_file.h>
#include <linux/sched.h>
#include <linux/sched/signal.h>

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Josue Nabi Hurtarte Pinto");
MODULE_DESCRIPTION("Sistemas Operativos 1 - Proyecto - Fase 2");
MODULE_VERSION("1.0");

/*
Estructura del archivo /proc/procesos_202202481
{
  "procesos_corriendo": 123,
  "total_procesos": 233,
  "procesos_durmiendo": 65,
  "procesos_zombies": 65,
  "procesos_parados": 65
}
*/

// Estados de procesos del kernel
#define TASK_RUNNING            0x00000000
#define TASK_INTERRUPTIBLE      0x00000001
#define TASK_UNINTERRUPTIBLE    0x00000002
#define __TASK_STOPPED          0x00000004
#define __TASK_TRACED           0x00000008
// Estados de salida
#define EXIT_DEAD               0x00000010
#define EXIT_ZOMBIE             0x00000020

// Funci√≥n que cuenta los procesos por estado
static void contar_procesos(int *corriendo, int *total, int *durmiendo, int *zombies, int *parados) {
    struct task_struct *task;
    
    // Inicializar contadores
    *corriendo = 0;
    *total = 0;
    *durmiendo = 0;
    *zombies = 0;
    *parados = 0;

    // Iterar sobre todos los procesos del sistema
    for_each_process(task) {
        (*total)++;
        
        // Verificar el estado del proceso
        if (task->__state == TASK_RUNNING) {
            (*corriendo)++;
        }
        else if (task->__state & (TASK_INTERRUPTIBLE | TASK_UNINTERRUPTIBLE)) {
            (*durmiendo)++;
        }
        else if (task->__state & (__TASK_STOPPED | __TASK_TRACED)) {
            (*parados)++;
        }
        
        // Verificar si es zombie
        if (task->exit_state & EXIT_ZOMBIE) {
            (*zombies)++;
        }
    }
}

// Funci√≥n que se llama cuando se lee el archivo /proc/procesos_202202481
static int mostrar_procesos(struct seq_file *archivo, void *v) {
    int procesos_corriendo, total_procesos, procesos_durmiendo, procesos_zombies, procesos_parados;
    
    // Obtener conteos de procesos
    contar_procesos(&procesos_corriendo, &total_procesos, &procesos_durmiendo, &procesos_zombies, &procesos_parados);
    
    // Generar salida en formato JSON
    seq_printf(archivo, "{\n");
    seq_printf(archivo, "  \"procesos_corriendo\": %d,\n", procesos_corriendo);
    seq_printf(archivo, "  \"total_procesos\": %d,\n", total_procesos);
    seq_printf(archivo, "  \"procesos_durmiendo\": %d,\n", procesos_durmiendo);
    seq_printf(archivo, "  \"procesos_zombies\": %d,\n", procesos_zombies);
    seq_printf(archivo, "  \"procesos_parados\": %d\n", procesos_parados);
    seq_printf(archivo, "}\n");
    
    return 0;
}

// Cuando se le hace un cat al m√≥dulo
static int abrir_proc(struct inode *inode, struct file *file) {
    return single_open(file, mostrar_procesos, NULL);
}

// Estructura de operaciones del archivo /proc/procesos_202202481
static const struct proc_ops procesos_ops = {
    .proc_open = abrir_proc,
    .proc_read = seq_read
};

// Funci√≥n de inicializaci√≥n del m√≥dulo
static int __init _insert(void) {
    proc_create("procesos_202202481", 0444, NULL, &procesos_ops);
    printk(KERN_INFO "Modulo Procesos cargado: /proc/procesos_202202481 creado\n");
    return 0;
}

// Funci√≥n de limpieza del m√≥dulo
static void __exit _delete(void) {
    remove_proc_entry("procesos_202202481", NULL);
    printk(KERN_INFO "Modulo Procesos descargado: /proc/procesos_202202481 eliminado\n");
}

module_init(_insert);
module_exit(_delete);
```

### Compilaci√≥n e instalaci√≥n del m√≥dulo

makefile:

```makefile
obj-m += procesos_202202481.o

all:
    make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules

clean:
    make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean
```

Compilaci√≥n:

```bash
# Navegar al directorio del m√≥dulo
cd Kernel/process/

# Limpiar compilaciones anteriores
make clean

# Compilar el m√≥dulo
make all
```

Instalacion:
```bash
# Cargar el m√≥dulo (requiere sudo)
sudo insmod procesos_202202481.ko

# Verificar que se carg√≥ correctamente
lsmod | grep procesos_202202481

# Verificar que el archivo /proc fue creado
ls -la /proc/procesos_202202481
```

## <a name="loc">4. Locust 

### üìã Objetivo de Locust en Fase 2

Locust en la Fase 2 implementa un **sistema de recolecci√≥n y distribuci√≥n de carga en dos etapas**, dise√±ado para probar tanto la capacidad de la VM como el traffic splitting del ingress. El objetivo es simular un flujo real de datos desde una fuente (VM) hacia un sistema distribuido (Kubernetes cluster).

### üöÄ Flujo de trabajo de Locust 

![locust_flow](./imgs/Locust.png)

### üìÑ Archivos de Locust

#### **1. traffic_collector.py - Recolector de datos de VM**

##### **üéØ Objetivo:**
Simular m√∫ltiples usuarios recolectando datos de la m√°quina virtual para generar carga y obtener m√©tricas reales del sistema bajo estr√©s. Este archivo act√∫a como **cliente de la VM** y **generador de datos**.

##### **‚öôÔ∏è Funcionalidades principales:**

- **Generaci√≥n de carga**: Simula 300+ usuarios concurrentes accediendo a la VM
- **Recolecci√≥n autom√°tica**: Obtiene m√©tricas de CPU, RAM y procesos en tiempo real
- **Almacenamiento estructurado**: Guarda datos en formato JSON para posterior procesamiento
- **Control de calidad**: Valida que los datos obtenidos sean completos y √∫tiles
- **L√≠mite inteligente**: Se detiene autom√°ticamente al alcanzar el objetivo de registros

##### **üîß Configuraci√≥n recomendada:**
```bash
locust -f traffic_collector.py --host=http://VM_IP:5200 \
       --users 300 --spawn-rate 1 --run-time 180s --headless
```

#### **2. traffic_splitter.py - Enviador de trafico**

##### **üéØ Objetivo:**

Probar el balanceador de carga NGINX enviando los datos recolectado al ingress del cluster kubernetes. Este archivo actua como cliente del cluster y validador del traffic splitting.  

##### **‚öôÔ∏è Funcionalidades principales:**

- **Datos √∫nicos**: Env√≠a datos √∫nicos para evitar duplicados en el sistema
- **Monitoreo de distribuci√≥n**: Rastrea que API proces√≥ cada peticion.
- **Estadisticas en tiempo real**: Muestra progreso y distribucion cada 50 registros.

##### **üîß Configuraci√≥n recomendada:**
```bash
locust -f send_to_ingress.py --host=http://INGRESS_IP \
       --users 150 --spawn-rate 1 --run-time 180s --headless
```

## <a name="kub">5. Kubernetes

### üìã Objetivo de Kubernetes en Fase 2

Google Kubernetes Engine (GKE) act√∫a como el **n√∫cleo de orquestaci√≥n** de la infraestructura cloud-native, administrando autom√°ticamente el despliegue, escalado y balanceo de carga de los microservicios. El cluster implementa una **arquitectura de servicios distribuidos** con alta disponibilidad y escalabilidad horizontal.

### üèóÔ∏è Arquitectura del Cluster GKE

```
Google Kubernetes Engine (GKE)
‚îú‚îÄ‚îÄ Namespace: sopes1-fase2
‚îú‚îÄ‚îÄ Deployment: python-api-deployment (1 replica)
‚îú‚îÄ‚îÄ Deployment: nodejs-api-deployment (1 replica)  
‚îú‚îÄ‚îÄ Deployment: nodejs-realtime-api-deployment (1 replica)
‚îú‚îÄ‚îÄ Deployment: metrics-proxy (NGINX - 1 replica)
‚îú‚îÄ‚îÄ Services: ClusterIP + NodePort
‚îî‚îÄ‚îÄ Ingress: External Load Balancer
```

### üèõÔ∏è Namespace: sopes1-fase2

#### **üéØ Prop√≥sito:**
Crear un **entorno aislado** dentro del cluster para todos los recursos del proyecto, proporcionando separaci√≥n l√≥gica y control de acceso granular.

#### **üìã Recursos contenidos:**
- **4 Deployments**: APIs Python, Node.js, Socket.io y NGINX proxy
- **4 Services**: Servicios internos para comunicaci√≥n entre pods
- **1 Ingress**: Load balancer externo para acceso p√∫blico
- **1 ConfigMap**: Configuraci√≥n de NGINX para traffic splitting

#### **üîß Ventajas del namespace:**
- **Aislamiento**: Separaci√≥n completa de otros proyectos
- **Gesti√≥n simplificada**: Operaciones agrupadas por namespace
- **Control de recursos**: L√≠mites de CPU/RAM por namespace
- **Seguridad**: Pol√≠ticas de red espec√≠ficas

### üê≥ Deployments (Pods)

#### **1. python-api-deployment**

##### **üéØ Funci√≥n:**
Despliegue de la **API Python Flask** para procesamiento de m√©tricas y almacenamiento en Cloud SQL.

##### **‚öôÔ∏è Configuraci√≥n clave:**
- **Imagen**: `josue013/sopes1-python-api:latest`
- **Puerto interno**: 5000
- **R√©plicas**: 1 (escalable horizontalmente)
- **Recursos**: 256Mi RAM, 0.25 CPU (l√≠mites: 512Mi, 0.5 CPU)
- **Health checks**: Liveness + Readiness probes en `/health`

##### **üîó Variables de entorno:**
- Conexi√≥n directa a Cloud SQL MySQL
- Credenciales de base de datos seguras
- Configuraci√≥n de puerto personalizable

---

#### **2. nodejs-api-deployment**

##### **üéØ Funci√≥n:**
Despliegue de la **API Node.js Express** como alternativa ligera para procesamiento r√°pido de m√©tricas y balanceo de carga con Python.

##### **‚öôÔ∏è Configuraci√≥n clave:**
- **Imagen**: `josue013/sopes1-nodejs-api:latest`
- **Puerto interno**: 3000
- **R√©plicas**: 1 (escalable horizontalmente)
- **Recursos**: 256Mi RAM, 0.25 CPU (l√≠mites: 512Mi, 0.5 CPU)
- **Health checks**: Liveness + Readiness probes en `/health`

##### **üîó Variables de entorno:**
- Misma base de datos que Python API (Cloud SQL)
- Configuraci√≥n id√©ntica para traffic splitting
- Puerto configurable via variable de entorno

---

#### **3. nodejs-realtime-api-deployment**

##### **üéØ Funci√≥n:**
Despliegue **especializado en tiempo real** con Socket.io para comunicaci√≥n bidireccional WebSocket con el frontend.

##### **‚öôÔ∏è Configuraci√≥n clave:**
- **Imagen**: `josue013/sopes1-nodejs-realtime-api:latest`
- **Puerto interno**: 4000
- **R√©plicas**: 1 (optimizado para WebSocket persistence)
- **Recursos**: 256Mi RAM, 0.25 CPU (l√≠mites: 512Mi, 0.5 CPU)
- **Health checks**: Verificaci√≥n de Socket.io endpoint

##### **üîó Caracter√≠sticas especiales:**
- **WebSocket support**: Configurado para Socket.io
- **CORS habilitado**: Para frontend en Cloud Run
- **Conexi√≥n persistente**: Mantiene estado de conexiones activas

---

#### **4. metrics-proxy (NGINX)**

##### **üéØ Funci√≥n:**
**Load balancer interno** que implementa traffic splitting 50/50 entre las APIs Python y Node.js, actuando como punto de entrada √∫nico.

##### **‚öôÔ∏è Configuraci√≥n clave:**
- **Imagen**: `nginx:alpine`
- **Puerto interno**: 80
- **R√©plicas**: 1 (punto √∫nico de entrada)
- **ConfigMap**: Configuraci√≥n NGINX personalizada
- **Upstream**: Round-robin entre python-api y nodejs-api

##### **üîó Rutas configuradas:**
- `/health` ‚Üí Python API (health check principal)
- `/metrics` ‚Üí Round-robin 50/50 (traffic splitting)
- `/debug` ‚Üí Informaci√≥n del balanceador
- `/` ‚Üí Status p√°gina del proxy

### üåê Services (Comunicaci√≥n Interna)

#### **Tipos de Services implementados:**

##### **1. ClusterIP Services (Comunicaci√≥n Interna)**

###### **python-api-service:**
- **Tipo**: ClusterIP (interno al cluster)
- **Puerto**: 80 ‚Üí 5000 (pod)
- **Funci√≥n**: Exponer Python API internamente
- **Acceso**: Solo desde otros pods del cluster

###### **nodejs-api-service:**
- **Tipo**: ClusterIP (interno al cluster)
- **Puerto**: 80 ‚Üí 3000 (pod)
- **Funci√≥n**: Exponer Node.js API internamente
- **Acceso**: Solo desde otros pods del cluster

###### **metrics-proxy-service:**
- **Tipo**: ClusterIP (interno al cluster)
- **Puerto**: 80 ‚Üí 80 (nginx pod)
- **Funci√≥n**: Exponer NGINX proxy internamente
- **Acceso**: Recibe tr√°fico del Ingress

##### **2. NodePort Service (Acceso Externo)**

###### **nodejs-realtime-api-service:**
- **Tipo**: NodePort (acceso externo directo)
- **Puerto**: 80 ‚Üí 4000 (pod)
- **NodePort**: 30080 (puerto fijo en nodos)
- **Funci√≥n**: Acceso directo para WebSockets
- **Motivo**: Bypass del Ingress para Socket.io

### üìä Flujo de comunicaci√≥n

#### **Tr√°fico interno (APIs REST):**
```
Ingress ‚Üí metrics-proxy-service ‚Üí NGINX Pod
   ‚Üì
NGINX (Round-robin) 
   ‚îú‚îÄ‚îÄ python-api-service ‚Üí Python Pod
   ‚îî‚îÄ‚îÄ nodejs-api-service ‚Üí Node.js Pod
```

#### **Tr√°fico WebSocket (Tiempo Real):**
```
Frontend ‚Üí NodeIP:30080 ‚Üí nodejs-realtime-api-service ‚Üí Socket.io Pod
```

### üîß Comandos de despliegue

#### **Creaci√≥n del cluster:**
```bash
# Crear cluster GKE optimizado
gcloud container clusters create sopes1-cluster \
  --zone=us-central1-a \
  --num-nodes=1 \
  --machine-type=n1-standard-2 \
  --enable-autoscaling \
  --max-nodes=3
```

#### **Configuraci√≥n del namespace:**
```bash
# Crear namespace dedicado
kubectl create namespace sopes1-fase2

# Establecer como namespace por defecto
kubectl config set-context --current --namespace=sopes1-fase2
```

#### **Despliegue de servicios:**
```bash
# Desplegar Python API
kubectl apply -f python.yaml

# Desplegar Node.js API
kubectl apply -f nodejs1.yaml

# Desplegar Socket.io API
kubectl apply -f nodejs2.yaml

# Desplegar NGINX Proxy + Ingress
kubectl apply -f ingress.yaml
```

#### **Verificaci√≥n del despliegue:**
```bash
# Verificar pods
kubectl get pods -n sopes1-fase2

# Verificar services
kubectl get services -n sopes1-fase2

# Verificar logs
kubectl logs deployment/python-api-deployment -n sopes1-fase2
```

### üéØ Ventajas de la implementaci√≥n en Kubernetes

- **Orquestaci√≥n autom√°tica**: Gesti√≥n de ciclo de vida de contenedores
- **Service discovery**: Comunicaci√≥n autom√°tica entre servicios
- **Load balancing**: Distribuci√≥n inteligente de carga
- **Health checks**: Verificaci√≥n autom√°tica de estado de servicios
- **Rolling updates**: Actualizaciones sin downtime
- **Resource management**: Control granular de CPU y memoria
- **Namespace isolation**: Separaci√≥n l√≥gica de recursos
- **Horizontal scaling**: Escalado autom√°tico bajo demanda

### üîç Monitoreo y debugging

#### **Estado del cluster:**
```bash
# Estado general
kubectl get all -n sopes1-fase2

# Descripci√≥n detallada de pods
kubectl describe pod <pod-name> -n sopes1-fase2

# Logs en tiempo real
kubectl logs -f deployment/python-api-deployment -n sopes1-fase2
```

#### **M√©tricas de recursos:**
```bash
# Uso de recursos por pod
kubectl top pods -n sopes1-fase2

# Uso de recursos por nodo
kubectl top nodes
```

La implementaci√≥n de Kubernetes en Fase 2 transforma la arquitectura de un sistema monol√≠tico hacia una **soluci√≥n cloud-native distribuida**, proporcionando la base s√≥lida para escalabilidad, alta disponibilidad y gesti√≥n automatizada de la infraestructura.

## <a name="ru">6. Rutas

### üìã Objetivo de las Rutas en Fase 2

El sistema implementa **dos rutas independientes** para el procesamiento y almacenamiento de m√©tricas del sistema, permitiendo **evaluaci√≥n comparativa de rendimiento** entre tecnolog√≠as Python y Node.js. Ambas rutas utilizan **comunicaci√≥n RPC** (Remote Procedure Call) para registrar datos eficientemente en Cloud SQL MySQL, implementando un **traffic splitting 50/50** a trav√©s del load balancer NGINX.

### üèóÔ∏è Arquitectura de Traffic Splitting

```
Locust/VM ‚Üí Ingress (Load Balancer) ‚Üí NGINX Proxy
                                          ‚Üì
                                    Round-robin 50/50
                                          ‚Üì
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                              ‚Üì                      ‚Üì
                        Ruta 1 (Python)      Ruta 2 (Node.js)
                         Flask API            Express API
                              ‚Üì                      ‚Üì
                        Cloud SQL MySQL ‚Üê ‚Üí Cloud SQL MySQL
                        (Misma instancia)     (Misma instancia)
```

### üõ£Ô∏è Ruta 1: API Python Flask

#### **üéØ Objetivo:**
Implementar un **servicio REST robusto** utilizando Python Flask para recibir m√©tricas del sistema y almacenarlas eficientemente en Cloud SQL MySQL. Esta ruta se enfoca en **procesamiento confiable** y **manejo avanzado de errores**.

#### **‚öôÔ∏è Caracter√≠sticas principales:**

##### **üîß Tecnolog√≠as utilizadas:**
- **Framework**: Flask (Python)
- **Base de datos**: PyMySQL (conector MySQL nativo)
- **CORS**: Flask-CORS para comunicaci√≥n cross-origin
- **Variables de entorno**: python-dotenv para configuraci√≥n segura
- **Logging**: Sistema de logs detallado con emojis para debugging

##### **üìä Endpoints implementados:**

###### **`GET /health` - Health Check**
- **Funci√≥n**: Verificaci√≥n de estado del servicio
- **Respuesta**: JSON con timestamp y estado del servicio
- **Uso**: Kubernetes health probes y monitoreo

###### **`POST /metrics` - Procesamiento de m√©tricas**
- **Funci√≥n**: Recibir y procesar m√©tricas del sistema
- **Entrada**: JSON con datos de CPU, RAM y procesos
- **Procesamiento**: 
  - Validaci√≥n de estructura JSON
  - Soporte para registros √∫nicos o arrays
  - Inserci√≥n en Cloud SQL con manejo de errores
- **Respuesta**: Confirmaci√≥n de registros procesados con identificaci√≥n de API

##### **üóÑÔ∏è Manejo de base de datos:**
```python
# Configuraci√≥n segura con variables de entorno
DB_CONFIG = {
    'host': os.getenv('DB_HOST'),
    'user': os.getenv('DB_USER'),
    'password': os.getenv('DB_PASSWORD'),
    'database': os.getenv('DB_NAME'),
    'port': int(os.getenv('DB_PORT')),
    'charset': 'utf8mb4'
}
```

##### **üìù Estructura de datos procesados:**
- **CPU**: Porcentaje de uso y porcentaje libre
- **RAM**: Total, usado, libre y porcentaje de uso
- **Procesos**: Conteos por estado (corriendo, durmiendo, zombie, parados)
- **Metadatos**: Timestamp autom√°tico y origen de datos (`python_api`)

##### **üîç Logging y monitoreo:**
```
üêç [PYTHON API] Datos recibidos: 1 registros
‚úÖ [PYTHON API] CPU: 45%, RAM: 67%, Procesos: 156
üêç [PYTHON API] Registro insertado exitosamente
```

---

### üõ£Ô∏è Ruta 2: API Node.js Express

#### **üéØ Objetivo:**
Implementar un **servicio REST de alto rendimiento** utilizando Node.js Express para recibir m√©tricas del sistema y almacenarlas eficientemente en Cloud SQL MySQL. Esta ruta se enfoca en **velocidad de procesamiento** y **escalabilidad horizontal**.

#### **‚öôÔ∏è Caracter√≠sticas principales:**

##### **üîß Tecnolog√≠as utilizadas:**
- **Framework**: Express.js (Node.js)
- **Base de datos**: mysql2/promise (conector moderno con soporte async/await)
- **CORS**: CORS middleware nativo
- **Variables de entorno**: dotenv para configuraci√≥n
- **Connection pooling**: Pool de conexiones para optimizaci√≥n

##### **üìä Endpoints implementados:**

###### **`GET /health` - Health Check**
- **Funci√≥n**: Verificaci√≥n de estado del servicio
- **Respuesta**: JSON con timestamp y identificaci√≥n del servicio
- **Uso**: Kubernetes health probes y balanceador de carga

###### **`POST /metrics` - Procesamiento de m√©tricas**
- **Funci√≥n**: Recibir y procesar m√©tricas del sistema con alta performance
- **Entrada**: JSON con datos de CPU, RAM y procesos
- **Procesamiento**:
  - Validaci√≥n as√≠ncrona de datos
  - Soporte para registros √∫nicos o arrays masivos
  - Inserci√≥n optimizada con connection pooling
- **Respuesta**: Confirmaci√≥n de registros procesados con identificaci√≥n de API

##### **üóÑÔ∏è Optimizaci√≥n de base de datos:**
```javascript
// Connection pool para alto rendimiento
const pool = mysql.createPool({
  host: process.env.DB_HOST,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD,
  database: process.env.DB_NAME,
  port: parseInt(process.env.DB_PORT),
  connectionLimit: 10,
  acquireTimeout: 60000,
  timeout: 60000,
});
```

##### **üìù Procesamiento as√≠ncrono:**
- **Async/Await**: Manejo moderno de operaciones as√≠ncronas
- **Connection pooling**: Reutilizaci√≥n eficiente de conexiones
- **Batch processing**: Soporte para inserci√≥n masiva de registros
- **Error handling**: Gesti√≥n robusta de errores con rollback autom√°tico

##### **üîç Logging y monitoreo:**
```
üü¢ [NODE API 1] Datos recibidos: 1 registros
üü¢ [NODE API 1] CPU: 45%, RAM: 67%, Procesos: 156
‚úÖ [NODE API 1] Insertados 1/1 registros
```

---

### üîÑ Traffic Splitting Implementation

#### **üìà Distribuci√≥n autom√°tica 50/50:**

El load balancer NGINX implementa **round-robin perfecto** entre las dos rutas:

```nginx
upstream backend_pool {
    server python-api-service:80 weight=1;
    server nodejs-api-service:80 weight=1;
}

location /metrics {
    proxy_pass http://backend_pool/metrics;
    # Configuraci√≥n de balanceo autom√°tico
}
```

#### **üìä Monitoreo de distribuci√≥n:**

Locust verifica que el traffic splitting funcione correctamente:

```
üìä Enviados: 1000/2000 (50.0%) | Python: 501 (50.1%) | Node.js: 499 (49.9%)
‚úÖ Traffic splitting funcionando correctamente dentro del margen ¬±2%
```

### üîß Configuraci√≥n de despliegue

#### **Variables de entorno compartidas:**
```bash
DB_HOST=34.61.65.213          # Cloud SQL IP privada
DB_USER=root                  # Usuario de base de datos
DB_PASSWORD=8AraHXK#EJL4\Fmq  # Password seguro
DB_NAME=sopes1_db            # Base de datos del proyecto
DB_PORT=3306                 # Puerto MySQL est√°ndar
```

#### **Comandos de despliegue:**
```bash
# Desplegar ambas rutas
kubectl apply -f python.yaml   # Ruta 1: Python Flask
kubectl apply -f nodejs1.yaml  # Ruta 2: Node.js Express

# Verificar funcionamiento
kubectl get pods -n sopes1-fase2
kubectl logs deployment/python-api-deployment -n sopes1-fase2
kubectl logs deployment/nodejs-api-deployment -n sopes1-fase2
```

### üéØ Resultados esperados

#### **Funcionalidad id√©ntica:**
- ‚úÖ Ambas rutas procesan los mismos datos de entrada
- ‚úÖ Ambas almacenan en la misma tabla de Cloud SQL
- ‚úÖ Ambas responden con el mismo formato JSON
- ‚úÖ Ambas implementan health checks compatibles

#### **Diferencias de implementaci√≥n:**
- **Python**: Enfoque en robustez y debugging
- **Node.js**: Enfoque en performance y escalabilidad
- **Traffic Split**: Distribuci√≥n equitativa autom√°tica
- **Observabilidad**: Logs diferenciados por tecnolog√≠a


La implementaci√≥n de rutas duales permite **optimizaci√≥n h√≠brida**, donde el sistema puede aprovechar las fortalezas de cada tecnolog√≠a seg√∫n los patrones de carga espec√≠ficos, mientras que el traffic splitting garantiza **distribuci√≥n equitativa** y **evaluaci√≥n comparativa objetiva** del rendimiento.

## <a name="sktio">7. Socket.io

### üìã Objetivo de Socket.io en Fase 2

Socket.io implementa un **sistema de comunicaci√≥n en tiempo real bidireccional** entre el cluster Kubernetes y el frontend desplegado en Cloud Run. El objetivo es proporcionar **actualizaciones instant√°neas** de m√©tricas del sistema sin necesidad de polling, creando una experiencia de usuario **reactiva y eficiente** con latencia m√≠nima.

### üèóÔ∏è Arquitectura de Tiempo Real

```
VM (Datos) ‚Üí APIs (Python/Node.js) ‚Üí Cloud SQL ‚Üí Socket.io API ‚Üí WebSocket ‚Üí Frontend (Cloud Run)
     ‚Üì              ‚Üì                    ‚Üì            ‚Üì              ‚Üì           ‚Üì
  M√©tricas    Almacenamiento        Persistencia   Tiempo Real    WSS/WS     Visualizaci√≥n
```

### üöÄ Flujo de Comunicaci√≥n WebSocket

#### **üì° Proceso de conexi√≥n:**
1. **Frontend se conecta** ‚Üí Socket.io server via NodePort (30080)
2. **Handshake inicial** ‚Üí Verificaci√≥n de CORS y autenticaci√≥n
3. **Datos inmediatos** ‚Üí Env√≠o de √∫ltimo registro de Cloud SQL
4. **Conexi√≥n persistente** ‚Üí Canal bidireccional establecido
5. **Actualizaciones autom√°ticas** ‚Üí Broadcast cada 2 segundos

### ‚öôÔ∏è API Node.js Socket.io Especializada

#### **üéØ Funci√≥n principal:**
Servicio **dedicado exclusivamente** a WebSockets que act√∫a como **puente en tiempo real** entre Cloud SQL y el frontend, proporcionando m√©tricas actualizadas sin latencia de polling tradicional.

#### **üîß Caracter√≠sticas t√©cnicas:**

##### **üìä Configuraci√≥n Socket.io:**
- **Framework**: Node.js + Express + Socket.io
- **Transports**: WebSocket + HTTP Long-polling (fallback)
- **CORS**: Configurado para Cloud Run domains
- **Conexiones**: M√∫ltiples clientes simult√°neos
- **Persistence**: Mantiene estado de conexiones activas

##### **üóÑÔ∏è Integraci√≥n con Cloud SQL:**
- **Connection Pool**: Pool optimizado de conexiones MySQL
- **Query optimizada**: SELECT con LIMIT 1 ORDER BY created_at DESC
- **Polling autom√°tico**: Verificaci√≥n cada 2 segundos de nuevos datos
- **Error handling**: Reconexi√≥n autom√°tica en caso de fallos DB

##### **üåê Configuraci√≥n CORS avanzada:**
```javascript
cors: {
  origin: [
    "http://localhost:5173",                    // Desarrollo local
    "https://sopes1-frontend-realtime-*.run.app", // Cloud Run din√°mico
    /^https:\/\/.*\.run\.app$/                  // Regex para dominios Cloud Run
  ],
  methods: ["GET", "POST"],
  credentials: true
}
```

### üìà Endpoints y Funcionalidades

#### **üîó WebSocket Events:**

##### **`connection` - Nueva Conexi√≥n**
- **Trigger**: Cliente se conecta al servidor
- **Acci√≥n**: 
  - Log de nueva conexi√≥n con ID √∫nico
  - Env√≠o inmediato de datos m√°s recientes
  - Registro en lista de clientes activos
- **Datos enviados**: √öltima m√©trica completa de Cloud SQL

##### **`metrics_update` - Actualizaci√≥n de M√©tricas**
- **Trigger**: Datos nuevos detectados en base de datos
- **Frecuencia**: Cada 2 segundos (configurable)
- **Payload**: JSON estructurado con m√©tricas completas
- **Broadcasting**: Env√≠o simult√°neo a todos los clientes conectados

##### **`disconnect` - Desconexi√≥n**
- **Trigger**: Cliente cierra conexi√≥n
- **Acci√≥n**: 
  - Log de desconexi√≥n
  - Limpieza de recursos asociados
  - Actualizaci√≥n de contador de clientes

#### **üîß REST Endpoints de soporte:**

##### **`GET /health` - Health Check**
- **Funci√≥n**: Verificaci√≥n de estado del servicio Socket.io
- **Respuesta**: Estado + contador de conexiones activas
- **Uso**: Kubernetes health probes y monitoreo

##### **`GET /api/metrics/latest` - Endpoint de respaldo**
- **Funci√≥n**: API REST tradicional para obtener datos
- **Uso**: Fallback en caso de problemas WebSocket
- **Respuesta**: Mismos datos que Socket.io pero via HTTP

### üîÑ Flujo de Datos en Tiempo Real

#### **üìä Estructura de datos transmitidos:**
```json
{
  "cpu": 48,
  "ram": 93,
  "ram_details": {
    "total": 3913,
    "used": 3648,
    "free": 265
  },
  "processes": {
    "total_procesos": 146,
    "procesos_corriendo": 16,
    "procesos_durmiendo": 128,
    "procesos_zombies": 2,
    "procesos_parados": 0
  },
  "data_source": "nodejs_api1",
  "timestamp": "2025-06-26T05:34:01.000Z"
}
```

#### **‚è±Ô∏è Ciclo de actualizaci√≥n autom√°tica:**
1. **Query a Cloud SQL** ‚Üí Obtener √∫ltimo registro cada 2s
2. **Comparaci√≥n de datos** ‚Üí Verificar si hay cambios
3. **Broadcasting** ‚Üí Enviar a todos los clientes conectados
4. **Logging** ‚Üí Registrar actividad de transmisi√≥n
5. **Repetir ciclo** ‚Üí Proceso continuo autom√°tico

### üåê Integraci√≥n Frontend (Cloud Run)

#### **üîó Cliente Socket.io en React:**

##### **üì° Configuraci√≥n de conexi√≥n:**
- **URL**: NodePort directo del cluster (bypass ingress)
- **Transports**: WebSocket preferido, polling como fallback
- **Auto-reconnect**: Reconexi√≥n autom√°tica en caso de desconexi√≥n
- **Event handlers**: Manejo de conexi√≥n, datos y errores

##### **‚öôÔ∏è Funcionalidades del cliente:**
- **Conexi√≥n autom√°tica**: Al cargar el dashboard
- **Callback registration**: Funci√≥n para actualizar UI
- **Error handling**: Manejo graceful de errores de conexi√≥n
- **Desconexi√≥n limpia**: Cleanup al salir del componente

##### **üéØ Ventajas sobre polling tradicional:**
- **Latencia reducida**: Actualizaciones instant√°neas sin delay
- **Eficiencia de red**: Sin requests HTTP constantes
- **Escalabilidad**: Una conexi√≥n por cliente vs m√∫ltiples requests
- **Experiencia de usuario**: UI m√°s fluida y responsiva

### üîß Despliegue y Configuraci√≥n

#### **üê≥ Deployment en Kubernetes:**
- **Imagen**: `josue013/sopes1-nodejs-realtime-api:latest`
- **Puerto**: 4000 (interno del pod)
- **Service**: NodePort 30080 (acceso externo directo)
- **R√©plicas**: 1 (optimizado para persistencia de conexiones)
- **Resources**: 256Mi RAM, 0.25 CPU

#### **üåê Acceso externo:**
- **Tipo**: NodePort (bypass del ingress para WebSockets)
- **Puerto externo**: 30080 (fijo en todos los nodos)
- **Protocolo**: HTTP/WebSocket (con upgrade autom√°tico)
- **Load balancing**: Directo a pod espec√≠fico

#### **üîó Variables de entorno:**
```bash
DB_HOST=34.61.65.213      # Cloud SQL IP privada
DB_USER=root              # Usuario MySQL
DB_PASSWORD=***           # Password seguro
DB_NAME=sopes1_db         # Base de datos del proyecto
PORT=4000                # Puerto interno del servicio
```

### üìä Monitoreo y Observabilidad

#### **üìà M√©tricas de Socket.io:**
- **Conexiones activas**: Contador en tiempo real
- **Messages per second**: Throughput de mensajes
- **Latencia de conexi√≥n**: Tiempo de establecimiento
- **Error rate**: Porcentaje de conexiones fallidas

#### **üîç Logging detallado:**
```
üöÄ Socket.io API corriendo en puerto: 4000
üü¢ Cliente conectado: abc123-def456
üìä Datos iniciales enviados a: abc123-def456
üì° Broadcasting datos a todos los clientes
üî¥ Cliente desconectado: abc123-def456
```

#### **‚ö†Ô∏è Health checks autom√°ticos:**
- **Kubernetes probes**: Verificaci√≥n de estado del pod
- **Connection counting**: Monitoreo de clientes activos
- **Database connectivity**: Verificaci√≥n de conexi√≥n a Cloud SQL
- **Memory usage**: Control de uso de recursos

### üéØ Ventajas de la Implementaci√≥n

#### **üöÄ Performance:**
- **Latencia ultra-baja**: <100ms entre dato nuevo y UI
- **Eficiencia de red**: 90% menos tr√°fico vs polling
- **Escalabilidad**: Soporte para cientos de clientes simult√°neos
- **Resource optimization**: Menor uso de CPU y memoria

#### **üë§ Experiencia de Usuario:**
- **Tiempo real genuino**: Sin retrasos perceptibles
- **UI responsiva**: Actualizaciones fluidas sin parpadeos
- **Conexi√≥n confiable**: Reconexi√≥n autom√°tica transparente
- **Datos siempre frescos**: Sin datos obsoletos

#### **üîß Arquitectura:**
- **Separaci√≥n de responsabilidades**: API dedicada solo a tiempo real
- **Escalabilidad independiente**: Escalar seg√∫n demanda WebSocket
- **Fault tolerance**: Fallback a REST API si WebSocket falla
- **Cloud-native**: Integraci√≥n nativa con Cloud Run y GKE

Socket.io en Fase 2 representa la **evoluci√≥n hacia arquitecturas de tiempo real**, transformando la experiencia tradicional de dashboards est√°ticos hacia **interfaces din√°micas y responsivas** que reflejan el estado del sistema instant√°neamente, proporcionando una **ventaja competitiva significativa** en observabilidad y monitoreo de sistemas.


## <a name="csql">8. Cloud SQL

### üìã Objetivo de Cloud SQL en Fase 2

Cloud SQL implementa una **base de datos MySQL totalmente administrada** por Google Cloud Platform, reemplazando la instancia local de MySQL de la Fase 1. El objetivo es proporcionar **alta disponibilidad**, **escalabilidad autom√°tica** y **administraci√≥n simplificada** de la base de datos, eliminando la necesidad de gesti√≥n manual de infraestructura.

### üèóÔ∏è Evoluci√≥n desde Fase 1

| **Aspecto**              | **Fase 1**                    | **Fase 2**                           |
|--------------------------|-------------------------------|--------------------------------------|
| **Tipo de servicio**    | MySQL en contenedor Docker    | Cloud SQL MySQL administrado        |
| **Administraci√≥n**      | Manual (configuraci√≥n, backups) | Autom√°tica (Google Cloud)           |
| **Escalabilidad**       | Limitada por recursos locales | Escalado autom√°tico bajo demanda    |
| **Alta disponibilidad** | Single point of failure       | Replicaci√≥n autom√°tica multi-zona   |
| **Backups**             | Manuales o scripts custom      | Backups autom√°ticos diarios         |
| **Monitoreo**           | Logs b√°sicos                   | M√©tricas integradas con GCP          |
| **Seguridad**           | Configuraci√≥n manual           | Cifrado autom√°tico y pol√≠ticas IAM  |

### üîß Configuraci√≥n de la Instancia

#### **üìä Especificaciones:**
- **Tipo**: Cloud SQL for MySQL 8.0
- **Instancia**: `db-n1-standard-1` (1 vCPU, 3.75 GB RAM)
- **Almacenamiento**: 20 GB SSD con auto-incremento habilitado
- **Regi√≥n**: `us-central1` (mismo que el cluster GKE)
- **Zona**: Multi-zona para alta disponibilidad
- **IP P√∫blica**: `34.61.65.213`

#### **üõ°Ô∏è Configuraci√≥n de seguridad:**
- **Conexiones autorizadas**: Acceso desde IPs espec√≠ficas y servicios GCP
- **SSL**: Conexiones cifradas obligatorias
- **Usuario root**: Configurado con password seguro
- **Backup autom√°tico**: Habilitado con retenci√≥n de 7 d√≠as
- **Maintenance window**: Configurado para horarios de baja actividad

### üóÑÔ∏è Estructura de la Base de Datos

#### **üèõÔ∏è Base de datos:** `sopes1_db`

La base de datos implementa una **tabla unificada** que consolida todas las m√©tricas del sistema en una sola estructura optimizada:

#### **üìä Tabla `system_metrics` (Unificada):**

```sql
CREATE TABLE IF NOT EXISTS system_metrics (
    id INT AUTO_INCREMENT PRIMARY KEY,
    ram_total BIGINT,
    ram_free BIGINT,
    ram_used BIGINT,
    ram_percentage FLOAT,
    cpu_usage FLOAT,
    cpu_free FLOAT,
    running_processes INT,
    total_processes INT,
    sleeping_processes INT,
    zombie_processes INT,
    stopped_processes INT,
    data_source VARCHAR(50),
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

#### **üîß Ventajas de la tabla unificada:**

##### **üìà Eficiencia de consultas:**
- **Single query**: Todas las m√©tricas en una sola consulta
- **Joins eliminados**: No necesidad de unir m√∫ltiples tablas
- **Performance optimizada**: √çndices optimizados para consultas temporales
- **Atomicidad**: Cada registro representa un snapshot completo del sistema

##### **üîç Facilidad de an√°lisis:**
- **Correlaci√≥n temporal**: Todas las m√©tricas tienen el mismo timestamp
- **An√°lisis integral**: Visualizaci√≥n completa del estado del sistema
- **Trending simplificado**: An√°lisis de tendencias m√°s directo
- **Reporting unificado**: Reportes consolidados sin complejidad

### üìä Campos y Tipos de Datos

| **Campo**              | **Tipo**        | **Descripci√≥n**                           |
|------------------------|-----------------|-------------------------------------------|
| `id`                   | `INT PK AUTO`   | Identificador √∫nico autoincremental      |
| `ram_total`            | `BIGINT`        | Memoria RAM total en MB                   |
| `ram_free`             | `BIGINT`        | Memoria RAM libre en MB                   |
| `ram_used`             | `BIGINT`        | Memoria RAM usada en MB                   |
| `ram_percentage`       | `FLOAT`         | Porcentaje de uso de RAM                  |
| `cpu_usage`            | `FLOAT`         | Porcentaje de uso de CPU                  |
| `cpu_free`             | `FLOAT`         | Porcentaje libre de CPU                   |
| `running_processes`    | `INT`           | N√∫mero de procesos en ejecuci√≥n          |
| `total_processes`      | `INT`           | Total de procesos en el sistema          |
| `sleeping_processes`   | `INT`           | Procesos en estado durmiendo             |
| `zombie_processes`     | `INT`           | Procesos zombie                          |
| `stopped_processes`    | `INT`           | Procesos parados                         |
| `data_source`          | `VARCHAR(50)`   | API que insert√≥ el registro              |
| `created_at`           | `DATETIME`      | Timestamp de inserci√≥n autom√°tico       |

### üîó Conectividad desde Kubernetes

#### **üîß Variables de entorno:**
```bash
DB_HOST=34.61.65.213      # IP p√∫blica de Cloud SQL
DB_USER=root              # Usuario de base de datos
DB_PASSWORD=***           # Password seguro generado
DB_NAME=sopes1_db         # Base de datos del proyecto
DB_PORT=3306              # Puerto MySQL est√°ndar
```

#### **üêç Conexi√≥n desde Python API:**
```python
import pymysql

DB_CONFIG = {
    'host': '34.61.65.213',
    'user': 'root',
    'password': os.getenv('DB_PASSWORD'),
    'database': 'sopes1_db',
    'port': 3306,
    'charset': 'utf8mb4'
}

connection = pymysql.connect(**DB_CONFIG)
```

#### **üü¢ Conexi√≥n desde Node.js APIs:**
```javascript
const mysql = require('mysql2/promise');

const pool = mysql.createPool({
    host: '34.61.65.213',
    user: 'root',
    password: process.env.DB_PASSWORD,
    database: 'sopes1_db',
    port: 3306,
    connectionLimit: 10
});
```




### üéØ Ventajas de Cloud SQL

#### **üöÄ Operacionales:**
- **Administraci√≥n cero**: Google gestiona updates, patches y maintenance
- **Escalabilidad autom√°tica**: Incremento de recursos bajo demanda
- **Alta disponibilidad**: 99.95% SLA con failover autom√°tico
- **Backups autom√°ticos**: Respaldos diarios con point-in-time recovery

#### **üõ°Ô∏è Seguridad:**
- **Cifrado en reposo**: Datos autom√°ticamente cifrados
- **Cifrado en tr√°nsito**: Conexiones SSL/TLS obligatorias
- **IAM integrado**: Control de acceso con pol√≠ticas de Google Cloud
- **Audit logs**: Registro completo de actividades

#### **üí∞ Econ√≥micas:**
- **Pay-as-you-use**: Pago por recursos consumidos
- **No upfront costs**: Sin inversi√≥n inicial en hardware
- **Optimizaci√≥n autom√°tica**: Ajuste autom√°tico de recursos
- **Reduced operational overhead**: Menor costo de administraci√≥n

### üîÑ Integraci√≥n con el Ecosistema

#### **üì° Flujo de datos:**
```
VM (M√≥dulos) ‚Üí APIs (Python/Node.js) ‚Üí Cloud SQL ‚Üí Socket.io ‚Üí Frontend
      ‚Üì                ‚Üì                    ‚Üì           ‚Üì          ‚Üì
   M√©tricas      Procesamiento        Persistencia   Tiempo Real  Visualizaci√≥n
```

#### **üéØ Casos de uso soportados:**
- **Inserci√≥n masiva**: Miles de registros por minuto via APIs
- **Consultas en tiempo real**: Socket.io obteniendo datos cada 2 segundos
- **An√°lisis hist√≥rico**: Dashboard con tendencias y estad√≠sticas
- **Monitoreo de salud**: Health checks de todas las APIs

Cloud SQL en Fase 2 representa la **transformaci√≥n hacia servicios administrados**, eliminando la complejidad operacional de la gesti√≥n de bases de datos mientras proporciona **enterprise-grade reliability** y **performance optimizada** para aplicaciones cloud-native modernas.

## <a name="crun">9. Cloud Run

### üìã Objetivo de Cloud Run en Fase 2

Cloud Run implementa un **servicio serverless completamente administrado** para el despliegue del frontend React. El objetivo es proporcionar una **plataforma de hosting escalable** que se ajuste autom√°ticamente a la demanda sin necesidad de gesti√≥n de infraestructura.

### üöÄ Caracter√≠sticas del servicio

#### **üê≥ Despliegue de contenedor:**
- **Imagen Docker**: Frontend React empaquetado en contenedor
- **Puerto interno**: 5173 (puerto est√°ndar de desarrollo Vite/React)
- **Protocolo**: HTTP/HTTPS autom√°tico
- **Escalado**: Autom√°tico de 0 a N instancias seg√∫n demanda

### üîß Configuraci√≥n del servicio

#### **üìä Especificaciones t√©cnicas:**
- **CPU**: 4 vCPU por instancia
- **Memoria**: 2gb por instancia
- **Concurrencia**: 80 requests por instancia
- **Timeout**: 300 segundos

#### **üåê Conectividad:**
- **URL p√∫blica**: Generada autom√°ticamente por Cloud Run
- **HTTPS**: Certificado SSL/TLS autom√°tico
- **Dominio personalizado**: Configurable si se requiere
- **Acceso**: P√∫blico (sin autenticaci√≥n requerida)

### üîó Integraci√≥n con el ecosistema

#### **üì° Conexiones del frontend:**
- **Socket.io**: Conexi√≥n directa al NodePort del cluster GKE (puerto 30080)
- **WebSockets**: Comunicaci√≥n en tiempo real para actualizaciones de m√©tricas
- **CORS**: Configurado en todas las APIs para permitir requests desde Cloud Run

### üéØ Ventajas de Cloud Run

#### **üöÄ Serverless:**
- **Escalado autom√°tico**: De 0 a miles de instancias autom√°ticamente
- **Pago por uso**: Solo se cobra por requests procesados
- **Gesti√≥n cero**: Google administra toda la infraestructura subyacente
- **Cold start**: Inicializaci√≥n r√°pida de nuevas instancias.

Cloud Run en Fase 2 proporciona una **soluci√≥n serverless moderna** para el frontend, eliminando la complejidad de gesti√≥n de servidores mientras ofrece **escalabilidad autom√°tica** y **alta disponibilidad** para la interfaz de usuario del sistema de monitoreo.

## üë®‚Äçüíª Autor

[@Josue013](https://www.github.com/Josue013)